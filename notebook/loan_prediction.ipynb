{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/config/workspace/dataset/train_u6lujuX_CVtuZ9i (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 13)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '0', '2', '3+'], dtype=object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Dependents'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dependents']=df['Dependents'].str.replace('3+','3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '0', '2', '3'], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Dependents'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dependents']=df['Dependents'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      394\n",
       "Female     86\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x = 'Gender',data = df)\n",
    "\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male numbers are more to apply for the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LP001011</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married  Dependents     Education Self_Employed  \\\n",
       "1  LP001003   Male     Yes           1      Graduate            No   \n",
       "2  LP001005   Male     Yes           0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes           0  Not Graduate            No   \n",
       "4  LP001008   Male      No           0      Graduate            No   \n",
       "5  LP001011   Male     Yes           2      Graduate           Yes   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "5             5417             4196.0       267.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  \n",
       "5             1.0         Urban           Y  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Y</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>N</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Y</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>N</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender Loan_Status  count\n",
       "0  Female           Y     54\n",
       "1  Female           N     32\n",
       "2    Male           Y    278\n",
       "3    Male           N    116"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Gender'],as_index=False)['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Y</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>N</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Y</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>N</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender Loan_Status  count\n",
       "0  Female           Y     54\n",
       "1  Female           N     32\n",
       "2    Male           Y    278\n",
       "3    Male           N    116"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Gender'],as_index=False)['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender is affecting for loan approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Married'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x = 'Married',data = df)\n",
    "\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Married</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>Y</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Y</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>N</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>N</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Married Loan_Status  count\n",
       "0      No           Y    105\n",
       "2     Yes           Y    227\n",
       "1      No           N     64\n",
       "3     Yes           N     84"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Married'],as_index=False)['Loan_Status'].value_counts().sort_values(by='Loan_Status',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marriend people of enough chances of getting loan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education\n",
       "Graduate        383\n",
       "Not Graduate     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>N</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>Y</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>N</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Education Loan_Status  count\n",
       "2  Not Graduate           Y     61\n",
       "3  Not Graduate           N     36\n",
       "0      Graduate           Y    271\n",
       "1      Graduate           N    112"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Education'],as_index=False)['Loan_Status'].value_counts().sort_values(by='Education',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Loan_ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we convert the categorical data into the numerical one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
       "       'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "['Male' 'Female']\n",
      "--------------------\n",
      "Married\n",
      "['Yes' 'No']\n",
      "--------------------\n",
      "Dependents\n",
      "[1 0 2 3]\n",
      "--------------------\n",
      "Education\n",
      "['Graduate' 'Not Graduate']\n",
      "--------------------\n",
      "Self_Employed\n",
      "['No' 'Yes']\n",
      "--------------------\n",
      "ApplicantIncome\n",
      "[ 4583  3000  2583  6000  5417  2333  3036  4006 12841  3200  3073  1853\n",
      "  1299  4950  3510  4887  7660  5955  2600  9560  2799  4226  1442  3167\n",
      "  4692  3500 12500  3667  4166  3748  3600  1800  3941  5649  5821  2645\n",
      "  4000  1928  3086  4230  4616 11500  2708  2132  3366  8080  3357  2500\n",
      "  3029  2609  5726 10750  7100  4300  3208  1875  5266  3750  1000  3846\n",
      "  1378  3988  2366  8566  5695  2958  6250  3273  4133  3620  2484  1977\n",
      "  4188  1759  4288  4843  3052 11417  3800  2071  5316 14583  5568 10408\n",
      "  2137  2957 10513  2014  2718  3459  4895  3316 14999  4200  5042  6950\n",
      "  2698 11757  2330 14866  1538 10000  4860  6277  2577  9166  2281  3254\n",
      " 39999  9538  1863  7933  3089  4167  9323  2439  2237  8000  3522  5708\n",
      "  4344  3497  2045  5516  6400  4600 33846  3625 39147  2178  9328  4885\n",
      " 12000  6033  3858  4191  3125  8333 11000  4923  3917  4408  3244  3975\n",
      "  2479  3418  3430  7787  5703  3173  3850   150  3727  2221  4009  2971\n",
      "  3250  2491  3155  5500  3812  3315  5819  2510  2965  3406  6050  9703\n",
      "  6608  2882  1809  1668  3427  2661 16250  3083  6045  5250 14683  2060\n",
      "  3481  7200  5166  4095  4708  4333  2876  3237 11146  2833  2620  3900\n",
      "  2750  3993  3103  4053  3927  2301  1811  3158  3704  4124  9508  3075\n",
      "  4400  3153  2383  6875  4666  5000  1625  3762  2400 20233  2917  2927\n",
      "  2507  3399  3717  4342 15000  8666  4917  5818  4384  2935  4160  2647\n",
      "  2378  4554  2499  2625  9083  8750  2666  2423  3875  5167  4723  4750\n",
      "  6822  6216  6325 19730 15759  5185  3062  4817  3069  5391  5941  7167\n",
      "  4566  2346  5488  9167  9504  1993  3100  3180  3033  3902  1500  2889\n",
      "  2755  1963  7441  4547  2167  2213  8300 81000  3867  6096  2253  2149\n",
      "  2995  1600  1025  3246  5829  1820 14880  4606  5935  2920  2717  8624\n",
      "  6500  2425  1926 10416  7142  3660  7901  4707 37719  3466  4652  3340\n",
      "  2309  3948  2483  7085  3859  4301  3708  4354  8334  7740  3015  2947\n",
      "  3450  2653  4691  5532 16525  6700 16667  4350  3095  2083 10833  1958\n",
      "  3547 18333  2435  3691 17263  3597  3326  2895  6283   645  3159  4865\n",
      "  3814 13262  3598  6065  3283  2130  5815  2031  4683  3400  2192  5677\n",
      "  7948 17500  3775  5285  2679  6783  4281  3588 18165  6133  3617  6417\n",
      "  4608  2138  2239  2768  3358  2526  2785  3333  2454  3593  5468 10139\n",
      "  3887  4180  3675 19484  5923  5800  8799  3166  3417 16666  6125  6406\n",
      "  3229  1782  6540  1836  2787  4283  2297  2165  2726 16120  3833  6383\n",
      "  9963  5780  3676  3987  3232  2900  4106  8072  7583]\n",
      "--------------------\n",
      "CoapplicantIncome\n",
      "[1.50800000e+03 0.00000000e+00 2.35800000e+03 4.19600000e+03\n",
      " 1.51600000e+03 2.50400000e+03 1.52600000e+03 1.09680000e+04\n",
      " 7.00000000e+02 8.10600000e+03 2.84000000e+03 1.08600000e+03\n",
      " 5.62500000e+03 1.91100000e+03 2.25300000e+03 1.04000000e+03\n",
      " 1.66700000e+03 3.00000000e+03 1.45900000e+03 7.21000000e+03\n",
      " 1.66800000e+03 1.21300000e+03 2.33600000e+03 3.44000000e+03\n",
      " 2.27500000e+03 1.64400000e+03 1.16700000e+03 1.59100000e+03\n",
      " 2.20000000e+03 2.25000000e+03 2.85900000e+03 3.79600000e+03\n",
      " 3.44900000e+03 4.59500000e+03 2.25400000e+03 3.06600000e+03\n",
      " 1.87500000e+03 1.77400000e+03 4.75000000e+03 3.02200000e+03\n",
      " 4.00000000e+03 1.88100000e+03 2.53100000e+03 2.11800000e+03\n",
      " 4.16700000e+03 2.90000000e+03 5.65400000e+03 1.82000000e+03\n",
      " 2.30200000e+03 9.97000000e+02 3.54100000e+03 3.26300000e+03\n",
      " 3.80600000e+03 1.03000000e+03 1.12600000e+03 3.60000000e+03\n",
      " 7.54000000e+02 2.28300000e+03 2.14200000e+03 8.98000000e+03\n",
      " 2.01400000e+03 3.85000000e+03 1.92900000e+03 7.75000000e+03\n",
      " 3.50000000e+03 1.43000000e+03 2.08300000e+03 2.03400000e+03\n",
      " 4.48600000e+03 1.42500000e+03 1.66600000e+03 8.30000000e+02\n",
      " 3.75000000e+03 1.04100000e+03 1.28000000e+03 1.44700000e+03\n",
      " 3.33300000e+03 7.36000000e+02 1.96400000e+03 1.61900000e+03\n",
      " 1.13000000e+04 1.45100000e+03 7.25000000e+03 2.58300000e+03\n",
      " 2.50000000e+03 1.08300000e+03 1.25000000e+03 3.02100000e+03\n",
      " 9.83000000e+02 1.80000000e+03 1.77500000e+03 1.71700000e+03\n",
      " 2.79100000e+03 1.69500000e+03 2.05400000e+03 1.77900000e+03\n",
      " 1.26000000e+03 5.00000000e+03 1.98300000e+03 5.70100000e+03\n",
      " 1.30000000e+03 4.41700000e+03 4.33300000e+03 1.84300000e+03\n",
      " 1.86800000e+03 3.89000000e+03 2.16700000e+03 7.10100000e+03\n",
      " 2.10000000e+03 2.20900000e+03 3.44700000e+03 1.38700000e+03\n",
      " 1.81100000e+03 1.56000000e+03 1.85700000e+03 2.22300000e+03\n",
      " 1.84200000e+03 3.27400000e+03 2.42600000e+03 8.00000000e+02\n",
      " 9.85799988e+02 3.05300000e+03 2.00000000e+03 2.41600000e+03\n",
      " 3.33400000e+03 2.54100000e+03 2.92500000e+03 2.93400000e+03\n",
      " 1.80300000e+03 1.86300000e+03 2.40500000e+03 1.64000000e+03\n",
      " 1.89000000e+02 4.98300000e+03 2.16000000e+03 2.45100000e+03\n",
      " 1.79300000e+03 4.60000000e+03 1.58700000e+03 1.22900000e+03\n",
      " 2.45800000e+03 2.16800000e+03 6.25000000e+03 5.05000000e+02\n",
      " 3.16700000e+03 3.66700000e+03 2.33300000e+03 5.26600000e+03\n",
      " 7.87300000e+03 1.98700000e+03 9.23000000e+02 4.99600000e+03\n",
      " 4.23200000e+03 1.60000000e+03 2.41700000e+03 1.62500000e+03\n",
      " 1.40000000e+03 2.00000000e+04 2.40000000e+03 2.03300000e+03\n",
      " 3.23700000e+03 2.77300000e+03 1.41700000e+03 1.71900000e+03\n",
      " 4.30000000e+03 1.61200008e+01 2.34000000e+03 1.85100000e+03\n",
      " 5.06400000e+03 1.83300000e+03 1.99300000e+03 1.21000000e+03\n",
      " 1.71000000e+03 1.25500000e+03 1.73300000e+03 2.46600000e+03\n",
      " 2.56900000e+03 2.18800000e+03 1.66400000e+03 2.07900000e+03\n",
      " 1.50000000e+03 4.64800000e+03 1.01400000e+03 1.75000000e+03\n",
      " 3.15000000e+03 2.43600000e+03 2.15700000e+03 9.13000000e+02\n",
      " 1.70000000e+03 4.41600000e+03 3.68300000e+03 5.62400000e+03\n",
      " 1.48300000e+03 3.01300000e+03 1.28700000e+03 2.00400000e+03\n",
      " 2.03500000e+03 6.66600000e+03 3.66600000e+03 3.42800000e+03\n",
      " 1.63200000e+03 1.91500000e+03 1.74200000e+03 1.42400000e+03\n",
      " 7.16600000e+03 1.30200000e+03 3.90600000e+03 5.36000000e+02\n",
      " 2.84500000e+03 2.52400000e+03 1.95000000e+03 1.78300000e+03\n",
      " 2.01600000e+03 3.25000000e+03 4.26600000e+03 1.03200000e+03\n",
      " 2.66900000e+03 2.30600000e+03 2.42000000e+02 2.06400000e+03\n",
      " 4.61000000e+02 2.73900000e+03 2.23200000e+03 3.38370000e+04\n",
      " 1.91700000e+03 1.52200000e+03 3.41600000e+03 3.30000000e+03\n",
      " 1.00000000e+03 4.30100000e+03 1.41100000e+03 2.40000000e+02]\n",
      "--------------------\n",
      "LoanAmount\n",
      "[128.  66. 120. 141. 267.  95. 158. 168. 349.  70. 200. 114.  17. 125.\n",
      "  76. 133. 104. 315. 116. 191. 122. 110.  35.  74. 106. 320. 144. 184.\n",
      "  80.  47. 134.  44. 100. 112. 286.  97.  96. 135. 180.  99. 165. 258.\n",
      " 126. 312. 136. 172.  81. 187. 113. 176. 111. 167.  50. 210. 175. 131.\n",
      " 188.  25. 137. 115. 151. 225. 216.  94. 185. 154. 259. 194. 160. 102.\n",
      " 290.  84.  88. 242. 129.  30. 118. 152. 244. 600. 255.  98. 275. 121.\n",
      "  75.  63.  87. 101. 495.  73. 260. 108.  48. 164. 170.  83.  90. 166.\n",
      " 124.  55.  59. 127. 214. 240. 130.  60. 280. 140. 155. 123. 201. 138.\n",
      " 279. 192. 304. 150. 207. 436.  78.  54.  89. 139.  93. 132. 480.  56.\n",
      " 300. 376.  67. 117.  71. 173.  46. 228. 308. 105. 236. 570. 380. 296.\n",
      " 156. 109. 103.  45.  65.  53. 360.  62. 218. 178. 239. 143. 148. 149.\n",
      " 153. 162. 230.  86. 234. 246. 500. 119. 107. 209. 208. 243.  40. 250.\n",
      " 311. 400. 161. 324. 157. 145. 181.  26. 182. 211.   9. 186. 205.  36.\n",
      " 146. 142. 496. 253.]\n",
      "--------------------\n",
      "Loan_Amount_Term\n",
      "[360. 120. 180.  60. 300. 480. 240.  36.  84.]\n",
      "--------------------\n",
      "Credit_History\n",
      "[1. 0.]\n",
      "--------------------\n",
      "Property_Area\n",
      "['Rural' 'Urban' 'Semiurban']\n",
      "--------------------\n",
      "Loan_Status\n",
      "['N' 'Y']\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i)\n",
    "    print(df[i].unique())\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender']=df['Gender'].map({'Male':0,\"Female\":1})\n",
    "df['Married']=df['Married'].map({'No':0,\"Yes\":1})\n",
    "df['Education']=df['Education'].map({'Not Graduate':0,'Graduate':1})\n",
    "df['Self_Employed']=df['Self_Employed'].map({'No':0,'Yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_Status\n",
       "Y    332\n",
       "N    148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Property_Area\n",
       "Semiurban    191\n",
       "Urban        150\n",
       "Rural        139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Property_Area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Loan_Status']=df['Loan_Status'].map({'N':0,'Y':1})\n",
    "df['Property_Area']=df['Property_Area'].map({'Semiurban':0,'Urban':1,'Rural':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 480 entries, 1 to 613\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Gender             480 non-null    int64  \n",
      " 1   Married            480 non-null    int64  \n",
      " 2   Dependents         480 non-null    int64  \n",
      " 3   Education          480 non-null    int64  \n",
      " 4   Self_Employed      480 non-null    int64  \n",
      " 5   ApplicantIncome    480 non-null    int64  \n",
      " 6   CoapplicantIncome  480 non-null    float64\n",
      " 7   LoanAmount         480 non-null    float64\n",
      " 8   Loan_Amount_Term   480 non-null    float64\n",
      " 9   Credit_History     480 non-null    float64\n",
      " 10  Property_Area      480 non-null    int64  \n",
      " 11  Loan_Status        480 non-null    int64  \n",
      "dtypes: float64(4), int64(8)\n",
      "memory usage: 48.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Loan_Status',axis=1)\n",
    "y=df['Loan_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "1       0        1           1          1              0             4583   \n",
       "2       0        1           0          1              1             3000   \n",
       "3       0        1           0          0              0             2583   \n",
       "4       0        0           0          1              0             6000   \n",
       "5       0        1           2          1              1             5417   \n",
       "\n",
       "   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "1             1508.0       128.0             360.0             1.0   \n",
       "2                0.0        66.0             360.0             1.0   \n",
       "3             2358.0       120.0             360.0             1.0   \n",
       "4                0.0       141.0             360.0             1.0   \n",
       "5             4196.0       267.0             360.0             1.0   \n",
       "\n",
       "   Property_Area  \n",
       "1              2  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  \n",
       "5              1  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle \n",
    "def scaler_standard(X_train,X_test):\n",
    "    scaler=StandardScaler()\n",
    "    X_train_scaled=scaler.fit_transform(X_train)\n",
    "    X_test_scaled=scaler.transform(X_test)\n",
    "\n",
    "    #Saving the model\n",
    "    file=open('/config/workspace/model/scaler.pkl','wb')\n",
    "    pickle.dump(scaler,file)\n",
    "    file.close()\n",
    "\n",
    "    return X_train_scaled,X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled,X_test_scaled=scaler_standard(X_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters={\n",
    "    'penalty':['l1', 'l2', 'elasticnet'],\n",
    "    'C': np.logspace(-3,3,7),\n",
    "    'solver':['lbfgs','liblinear','newton'] \n",
    "\n",
    "}\n",
    "grid= GridSearchCV(LogisticRegression(), param_grid=parameters, cv = 5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "210 fits failed out of a total of 315.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "105 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'solver' parameter of LogisticRegression must be a str among {'newton-cholesky', 'saga', 'lbfgs', 'newton-cg', 'sag', 'liblinear'}. Got 'newton' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.29425837        nan 0.70574163 0.81780588        nan\n",
      "        nan        nan        nan        nan 0.29425837        nan\n",
      " 0.79432673 0.82040328        nan        nan        nan        nan\n",
      "        nan 0.81780588        nan 0.82040328 0.82040328        nan\n",
      "        nan        nan        nan        nan 0.82040328        nan\n",
      " 0.82300068 0.82300068        nan        nan        nan        nan\n",
      "        nan 0.82300068        nan 0.82559809 0.82559809        nan\n",
      "        nan        nan        nan        nan 0.82559809        nan\n",
      " 0.82559809 0.82559809        nan        nan        nan        nan\n",
      "        nan 0.82559809        nan 0.82559809 0.82559809        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'newton']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf=LogisticRegression(C=10.0,penalty='l2',solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10.0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log_pred=log_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708333333333334\n",
      "[[14 21]\n",
      " [ 1 60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.40      0.56        35\n",
      "           1       0.74      0.98      0.85        61\n",
      "\n",
      "    accuracy                           0.77        96\n",
      "   macro avg       0.84      0.69      0.70        96\n",
      "weighted avg       0.81      0.77      0.74        96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "print(accuracy_score(y_test, y_log_pred))\n",
    "print(confusion_matrix(y_test, y_log_pred))\n",
    "print(classification_report(y_test, y_log_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "parameters={\n",
    "    'criterion' : ['gini','entropy','log_loss'],\n",
    "    'splitter' : ['best','random'],\n",
    "    'max_depth' : [1,2,3,4,5],\n",
    "    'max_features' : ['auto','sqrt','log2']\n",
    "\n",
    "}\n",
    "grid=GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,cv=5,verbose=3,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=best;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=random;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1, max_features=sqrt, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=1, max_features=log2, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1, max_features=log2, splitter=best;, score=0.662 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1, max_features=log2, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1, max_features=log2, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1, max_features=log2, splitter=best;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=1, max_features=log2, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=1, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=1, max_features=log2, splitter=random;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=1, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=1, max_features=log2, splitter=random;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=best;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=best;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=best;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, splitter=random;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, splitter=best;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, splitter=random;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=0.675 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=best;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, max_features=sqrt, splitter=random;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=0.636 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=0.662 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, max_features=log2, splitter=best;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=3, max_features=log2, splitter=random;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=0.623 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=best;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=sqrt, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=0.662 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=0.662 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=log2, splitter=best;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=4, max_features=log2, splitter=random;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=best;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=0.636 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, splitter=random;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, splitter=best;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, splitter=random;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=best;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1, max_features=sqrt, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=best;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=1, max_features=log2, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=best;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=random;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=random;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=random;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, splitter=random;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=best;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=best;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=0.649 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, max_features=sqrt, splitter=random;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=best;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=3, max_features=log2, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=0.688 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=best;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=sqrt, splitter=random;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=best;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=4, max_features=log2, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=best;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=0.649 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, splitter=random;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=best;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=1, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=best;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=best;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=1, max_features=sqrt, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=best;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=best;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=1, max_features=log2, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=best;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=best;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, splitter=random;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=best;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=best;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, splitter=random;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=best;, score=0.829 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, max_features=sqrt, splitter=random;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=0.662 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=best;, score=0.697 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=0.662 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=3, max_features=log2, splitter=random;, score=0.868 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=4, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=best;, score=0.645 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=4, max_features=sqrt, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=0.857 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=best;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=4, max_features=log2, splitter=random;, score=0.868 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=best;, score=0.816 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=0.831 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=0.831 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, splitter=random;, score=0.855 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=0.818 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=best;, score=0.868 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, splitter=random;, score=0.803 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "150 fits failed out of a total of 450.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/config/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/config/.local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.72392344 0.72652085 0.69794942 0.7398838\n",
      "        nan        nan 0.78403964 0.77344498 0.76291866 0.7424812\n",
      "        nan        nan 0.77863978 0.76565277 0.68520164 0.75762133\n",
      "        nan        nan 0.73202324 0.76052632 0.75792891 0.77074504\n",
      "        nan        nan 0.76828435 0.76045796 0.78403964 0.79692413\n",
      "        nan        nan 0.76028708 0.72132604 0.74989747 0.73431306\n",
      "        nan        nan 0.75533151 0.71910458 0.75027341 0.76028708\n",
      "        nan        nan 0.75252905 0.72645249 0.76845523 0.78626111\n",
      "        nan        nan 0.7424812  0.80471634 0.76052632 0.80468216\n",
      "        nan        nan 0.78393712 0.77098428 0.77351333 0.79688995\n",
      "        nan        nan 0.70574163 0.74210526 0.74470267 0.72652085\n",
      "        nan        nan 0.80741627 0.75806562 0.72915243 0.78386876\n",
      "        nan        nan 0.80215311 0.81520848 0.7524607  0.74251538\n",
      "        nan        nan 0.75492139 0.7758715  0.76828435 0.79706083\n",
      "        nan        nan 0.78913192 0.81780588 0.78926863 0.76831852]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'log_loss',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_clf=DecisionTreeClassifier(criterion='entropy',max_depth=4,max_features='log2',splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=4, max_features=&#x27;log2&#x27;,\n",
       "                       splitter=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=4, max_features=&#x27;log2&#x27;,\n",
       "                       splitter=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features='log2',\n",
       "                       splitter='random')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_decision_pred=decision_tree_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_decision_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7395833333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.78      0.53        18\n",
      "           1       0.93      0.73      0.82        78\n",
      "\n",
      "    accuracy                           0.74        96\n",
      "   macro avg       0.67      0.75      0.67        96\n",
      "weighted avg       0.83      0.74      0.77        96\n",
      "\n",
      "[[14  4]\n",
      " [21 57]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_decision_pred, y_test))\n",
    "print(classification_report(y_decision_pred, y_test))\n",
    "print(confusion_matrix(y_decision_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "gnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" checked><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Naives_pred = gnb.predict(X_test)\n",
    "y_Naives_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604166666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.88      0.55        16\n",
      "           1       0.97      0.74      0.84        80\n",
      "\n",
      "    accuracy                           0.76        96\n",
      "   macro avg       0.68      0.81      0.69        96\n",
      "weighted avg       0.87      0.76      0.79        96\n",
      "\n",
      "[[14  2]\n",
      " [21 59]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_Naives_pred, y_test))\n",
    "print(classification_report(y_Naives_pred, y_test))\n",
    "print(confusion_matrix(y_Naives_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('/config/workspace/model/model_prediction.pkl','wb')\n",
    "pickle.dump(decision_tree_clf,file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
